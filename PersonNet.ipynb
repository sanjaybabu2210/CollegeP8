{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PersonNet.ipynb",
      "provenance": [],
      "mount_file_id": "16LQ7K0JFoSF0YL1CrY2W-CbPpElA0FFQ",
      "authorship_tag": "ABX9TyOToq0oh5L5MTNoEOfDMewy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allenalvin333/CollegeP8/blob/Zil/PersonNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vr76i6G1g589",
        "outputId": "94b751b6-7cc7-4945-935b-7c7435632934"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDkBrHoTlEhM"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Input, ReLU, UpSampling2D\n",
        "#from keras.layers import BatchNormalization, Dropout,  ELU\n",
        "from keras.layers import Add, Concatenate, Lambda, Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from PIL import Image\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPUp2QnAzsHM"
      },
      "source": [
        "def upsample_neighbour(input_x):\n",
        "    input_x_padded = K.spatial_2d_padding(input_x, padding=((2,2),(2,2)))\n",
        "    width = K.int_shape(input_x)[1]\n",
        "    height = K.int_shape(input_x)[2]\n",
        "    output_x_list = []\n",
        "    output_y_list = []\n",
        "    for i_x in range(2, width + 2):\n",
        "        for i_y in range(2, height + 2):\n",
        "            output_y_list.append(input_x_padded[:,i_x-2:i_x+3,i_y-2:i_y+3,:])\n",
        "        output_x_list.append(K.concatenate(output_y_list, axis=2))\n",
        "        output_y_list = []\n",
        "    return K.concatenate(output_x_list, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RxRbZlqz7rp"
      },
      "source": [
        "def get_classification_model(input_shape=(128,64,3), print_summary=True, weight_decay=0.0005, dropout_rate=0):\n",
        "    #input_shape=(160,60,3)\n",
        "    x1_input = Input(shape=input_shape, name='input1')\n",
        "    x2_input = Input(shape=input_shape, name='input2')\n",
        "    conv1_tied = Conv2D(20, 5, kernel_regularizer=l2(weight_decay), activation=\"relu\", name='conv1_tied')\n",
        "    x1 = conv1_tied(x1_input)\n",
        "    x2 = conv1_tied(x2_input)\n",
        "    x1 = MaxPool2D(pool_size=2, padding='same', name='maxpool_f1')(x1)\n",
        "    x2 = MaxPool2D(pool_size=2, padding='same', name='maxpool_g1')(x2)\n",
        "    if dropout_rate > 0:\n",
        "        x1 = Dropout(dropout_rate, name='dropout_x1_1')(x1)\n",
        "        x2 = Dropout(dropout_rate, name='dropout_x2_1')(x2)\n",
        "    conv2_tied = Conv2D(25, 5, kernel_regularizer=l2(weight_decay), activation=\"relu\", name='conv2_tied')\n",
        "    x1 = conv2_tied(x1)\n",
        "    x2 = conv2_tied(x2)\n",
        "    x1 = MaxPool2D(pool_size=2, padding='same', name='maxpool_f2')(x1)\n",
        "    x2 = MaxPool2D(pool_size=2, padding='same', name='maxpool_g2')(x2)\n",
        "    if dropout_rate > 0:\n",
        "        x1 = Dropout(dropout_rate, name='dropout_x1_2')(x1)\n",
        "        x2 = Dropout(dropout_rate, name='dropout_x2_2')(x2)\n",
        "    f1 = UpSampling2D(size=(5,5), name='upsample_f1')(x1)\n",
        "    g1 = Lambda(upsample_neighbour, name='upsample_neighbour_g1')(x2)\n",
        "    g1 = Lambda(lambda x : -x, name='negate_g1')(g1)\n",
        "    k1 = Add(name='add_k1')([f1, g1])\n",
        "    f2 = UpSampling2D(size=(5,5), name='upsample_f2')(x2)\n",
        "    g2 = Lambda(upsample_neighbour, name='upsample_neighbour_g2')(x1)\n",
        "    g2 = Lambda(lambda x : -x, name='negate_g2')(g2)\n",
        "    k2 = Add(name='add_k2')([f2, g2])\n",
        "    k1 = ReLU(name='relu_k1')(k1)\n",
        "    k2 = ReLU(name='relu_k2')(k2)\n",
        "    k1 = Conv2D(25, 5, strides=(5,5), kernel_regularizer=l2(weight_decay), activation=\"relu\", name='patch_summary_k1')(k1)\n",
        "    k2 = Conv2D(25, 5, strides=(5,5), kernel_regularizer=l2(weight_decay), activation=\"relu\", name='patch_summary_k2')(k2)\n",
        "    k1 = Conv2D(25, 3, kernel_regularizer=l2(weight_decay), activation=\"relu\", name='accross_patch_conv_k1')(k1)\n",
        "    k2 = Conv2D(25, 3, kernel_regularizer=l2(weight_decay), activation=\"relu\", name='accross_patch_conv_k2')(k2)\n",
        "    k1 = MaxPool2D(pool_size=2, padding='same', name='maxpool_k1')(k1)\n",
        "    k2 = MaxPool2D(pool_size=2, padding='same', name='maxpool_k2')(k2)\n",
        "    if dropout_rate > 0:\n",
        "        k1 = Dropout(dropout_rate, name='dropout_k1')(k1)\n",
        "        k2 = Dropout(dropout_rate, name='dropout_k2')(k2)\n",
        "    k1 = Flatten(name='flatten_k1')(k1)\n",
        "    k2 = Flatten(name='flatten_k2')(k2)\n",
        "    y = Concatenate(name='concat_k1_and_k2')([k1, k2])\n",
        "    y = Dense(units=500, kernel_regularizer=l2(weight_decay), activation=\"relu\")(y)\n",
        "    if dropout_rate > 0:\n",
        "        y = Dropout(dropout_rate, name='dropout_y')(y)\n",
        "    y_out = Dense(units=2, kernel_regularizer=l2(weight_decay), activation=\"softmax\")(y)\n",
        "    model = Model(inputs=[x1_input, x2_input], outputs=[y_out])\n",
        "    if print_summary == True:\n",
        "        model.summary()     \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUpAFmxk1mva"
      },
      "source": [
        "def prepare_dataset(file_path = '/content/drive/MyDrive/Dataset/', img_format='jpg'):\n",
        "    #prepare_dataset\n",
        "    filePaths = file_path + '*.' + img_format\n",
        "    distinct_identities = 1467\n",
        "    all_images = [list() for _ in range(distinct_identities)]\n",
        "    for filename in sorted(glob.glob(filePaths)):\n",
        "        identity_num = int(filename.split('/')[-1].split('_')[0])\n",
        "        assert identity_num < distinct_identities\n",
        "        im=Image.open(filename)\n",
        "        all_images[identity_num].append(np.array(im)/255.0)\n",
        "    return all_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3kLbEM2EtE"
      },
      "source": [
        "def generate_random_train(all_images, batch_size_big=64):\n",
        "    batch_size = batch_size_big//2\n",
        "    while True:\n",
        "        np.random.rand(0,len(all_images), batch_size//2)\n",
        "        left_imgs = np.empty([2*batch_size, 128, 64, 3])\n",
        "        right_imgs = np.empty([2*batch_size, 128, 64, 3])\n",
        "        y = np.empty([2*batch_size, 2])\n",
        "        a = np.arange(1000)\n",
        "        np.random.shuffle(a)\n",
        "        inds = a[:batch_size]        \n",
        "        for batch_ind, cur_img_ind in enumerate(inds):\n",
        "            b = np.arange(len(all_images[cur_img_ind]))\n",
        "            np.random.shuffle(b)\n",
        "            inds_same = b[:2]\n",
        "            #print(batch_ind, cur_img_ind, inds_same[0])\n",
        "            left_imgs[batch_ind]\n",
        "            all_images[cur_img_ind]\n",
        "            all_images[cur_img_ind][inds_same[0]]\n",
        "            left_imgs[batch_ind] = all_images[cur_img_ind][inds_same[0]]\n",
        "            right_imgs[batch_ind] = all_images[cur_img_ind][inds_same[1]]\n",
        "            y[batch_ind] = np.array([1,0])\n",
        "            a = np.arange(1000)\n",
        "            np.random.shuffle(a)\n",
        "            inds = a[:2*batch_size]        \n",
        "            for batch_ind in range(0,2*batch_size, 2):\n",
        "                left_imgs[batch_size + batch_ind//2] = all_images[inds[batch_ind]][np.random.randint(len(all_images[inds[batch_ind]]))]\n",
        "                right_imgs[batch_size + batch_ind//2] = all_images[inds[batch_ind+1]][np.random.randint(len(all_images[inds[batch_ind+1]]))]\n",
        "                y[batch_size + batch_ind//2] = np.array([0,1]) \n",
        "            rng_state = np.random.get_state()\n",
        "            np.random.shuffle(left_imgs)\n",
        "            np.random.set_state(rng_state)\n",
        "            np.random.shuffle(right_imgs)\n",
        "            np.random.set_state(rng_state)\n",
        "            np.random.shuffle(y)\n",
        "            yield [left_imgs, right_imgs], y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyH1elBm2bpZ"
      },
      "source": [
        "def generate_random_val(all_images, batch_size_big=64):\n",
        "    batch_size = batch_size_big//2\n",
        "    while True:\n",
        "        np.random.rand(0,len(all_images), batch_size//2)\n",
        "        left_imgs = np.empty([batch_size*2, 128, 64, 3])\n",
        "        right_imgs = np.empty([batch_size*2, 128, 64, 3])\n",
        "        y = np.empty([2*batch_size, 2])\n",
        "        a = np.arange(1000, 1200, 1)\n",
        "        np.random.shuffle(a)\n",
        "        inds = a[:batch_size]        \n",
        "        for batch_ind, cur_img_ind in enumerate(inds):\n",
        "            b = np.arange(len(all_images[cur_img_ind]))\n",
        "            np.random.shuffle(b)\n",
        "            inds_same = b[:2]\n",
        "            #print(batch_ind, cur_img_ind, inds_same[0])\n",
        "            left_imgs[batch_ind]\n",
        "            all_images[cur_img_ind]\n",
        "            all_images[cur_img_ind][inds_same]\n",
        "            left_imgs[batch_ind] = all_images[cur_img_ind][inds_same[0]]\n",
        "            right_imgs[batch_ind] = all_images[cur_img_ind][inds_same[1]]\n",
        "            y[batch_ind] = np.array([1,0])\n",
        "        a = np.arange(1000, 1200, 1)\n",
        "        np.random.shuffle(a)\n",
        "        inds = a[:2*batch_size]        \n",
        "        for batch_ind in range(0,2*batch_size, 2):\n",
        "            left_imgs[batch_size + batch_ind//2] = all_images[inds[batch_ind]][np.random.randint(len(all_images[inds[batch_ind]]))]\n",
        "            right_imgs[batch_size + batch_ind//2] = all_images[inds[batch_ind+1]][np.random.randint(len(all_images[inds[batch_ind+1]]))]\n",
        "            y[batch_size + batch_ind//2] = np.array([0,1])\n",
        "        rng_state = np.random.get_state()\n",
        "        np.random.shuffle(left_imgs)\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(right_imgs)\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(y)\n",
        "        yield [left_imgs, right_imgs], y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e2PbdgdT8HjS",
        "outputId": "9db44b0f-7fbe-42c9-d3da-db4eb77ce785"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # TODO if model_path argument then load model from weights else train new model\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # help_ = \"Load h5 model trained weights\"\n",
        "    # parser.add_argument(\"-w\", \"--weights\", help=help_)\n",
        "    # args = parser.parse_args()\n",
        "    all_images = prepare_dataset()\n",
        "    model = get_classification_model(dropout_rate=0.5)\n",
        "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    gen_tr = generate_random_train(all_images=all_images, batch_size_big=60)\n",
        "    gen_val = generate_random_val(all_images=all_images, batch_size_big=60)\n",
        "    model_checkpoint_dir = 'models_dp05_epoch200'\n",
        "    model_checkpoint_name = 'dropout_05'\n",
        "    checkpoint_path = os.path.join(model_checkpoint_dir, model_checkpoint_name + '.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
        "    epochs = 150\n",
        "    callbacks_list= [ModelCheckpoint(save_best_only=False,filepath=checkpoint_path),TensorBoard(log_dir='logs')]\n",
        "    history = model.fit(gen_tr,steps_per_epoch=200,\n",
        "                                  epochs=epochs,\n",
        "                                  validation_data=gen_val,\n",
        "                                  validation_steps=1,\n",
        "                                  callbacks=callbacks_list)\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    plt.plot(range(epochs), loss, color='red', label='training')\n",
        "    plt.plot(range(epochs), val_loss, color='orange', label='validation')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    plt.plot(range(epochs), acc, color='red', label='training')\n",
        "    plt.plot(range(epochs), val_acc, color='orange', label='validation')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             [(None, 128, 64, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input2 (InputLayer)             [(None, 128, 64, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_tied (Conv2D)             (None, 124, 60, 20)  1520        input1[0][0]                     \n",
            "                                                                 input2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_f1 (MaxPooling2D)       (None, 62, 30, 20)   0           conv1_tied[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_g1 (MaxPooling2D)       (None, 62, 30, 20)   0           conv1_tied[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_x1_1 (Dropout)          (None, 62, 30, 20)   0           maxpool_f1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_x2_1 (Dropout)          (None, 62, 30, 20)   0           maxpool_g1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_tied (Conv2D)             (None, 58, 26, 25)   12525       dropout_x1_1[0][0]               \n",
            "                                                                 dropout_x2_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_f2 (MaxPooling2D)       (None, 29, 13, 25)   0           conv2_tied[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_g2 (MaxPooling2D)       (None, 29, 13, 25)   0           conv2_tied[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_x1_2 (Dropout)          (None, 29, 13, 25)   0           maxpool_f2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_x2_2 (Dropout)          (None, 29, 13, 25)   0           maxpool_g2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "upsample_neighbour_g1 (Lambda)  (None, 145, 65, 25)  0           dropout_x2_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "upsample_neighbour_g2 (Lambda)  (None, 145, 65, 25)  0           dropout_x1_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "upsample_f1 (UpSampling2D)      (None, 145, 65, 25)  0           dropout_x1_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "negate_g1 (Lambda)              (None, 145, 65, 25)  0           upsample_neighbour_g1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "upsample_f2 (UpSampling2D)      (None, 145, 65, 25)  0           dropout_x2_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "negate_g2 (Lambda)              (None, 145, 65, 25)  0           upsample_neighbour_g2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_k1 (Add)                    (None, 145, 65, 25)  0           upsample_f1[0][0]                \n",
            "                                                                 negate_g1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_k2 (Add)                    (None, 145, 65, 25)  0           upsample_f2[0][0]                \n",
            "                                                                 negate_g2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "relu_k1 (ReLU)                  (None, 145, 65, 25)  0           add_k1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu_k2 (ReLU)                  (None, 145, 65, 25)  0           add_k2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "patch_summary_k1 (Conv2D)       (None, 29, 13, 25)   15650       relu_k1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "patch_summary_k2 (Conv2D)       (None, 29, 13, 25)   15650       relu_k2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "accross_patch_conv_k1 (Conv2D)  (None, 27, 11, 25)   5650        patch_summary_k1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "accross_patch_conv_k2 (Conv2D)  (None, 27, 11, 25)   5650        patch_summary_k2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_k1 (MaxPooling2D)       (None, 14, 6, 25)    0           accross_patch_conv_k1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "maxpool_k2 (MaxPooling2D)       (None, 14, 6, 25)    0           accross_patch_conv_k2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_k1 (Dropout)            (None, 14, 6, 25)    0           maxpool_k1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_k2 (Dropout)            (None, 14, 6, 25)    0           maxpool_k2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_k1 (Flatten)            (None, 2100)         0           dropout_k1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_k2 (Flatten)            (None, 2100)         0           dropout_k2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concat_k1_and_k2 (Concatenate)  (None, 4200)         0           flatten_k1[0][0]                 \n",
            "                                                                 flatten_k2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 500)          2100500     concat_k1_and_k2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_y (Dropout)             (None, 500)          0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 2)            1002        dropout_y[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,158,147\n",
            "Trainable params: 2,158,147\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-205168605aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                   callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-2c8e6020b131>\u001b[0m in \u001b[0;36mgenerate_random_train\u001b[0;34m(all_images, batch_size_big)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mleft_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mall_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_img_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mall_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_img_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_same\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mleft_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_img_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_same\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mright_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_img_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_same\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    }
  ]
}